---
title: Automated Captions using the Live API
description: In this topic you will learn how to use the Live API to enable automated captions in your live stream.
parent: Guides
grandparent: Live API
layout: staging
---
<h1>{{ page.title }}</h1>
<article class="bcls-article">
  <summary>{{ page.description }}</summary>

  <section class="bcls-section">
    <h2 id="Introduction">Introduction</h2>
    <p>The automated captions feature allows you to enable automatic audio transcribing to create captions for your live stream.</p>
    <p>If you are new to the Live API, review the <a href="/live-api/getting-started/quick-start-create-live-stream-using-brightcove-live-api.html">Create a Live Stream Using the Brightcove Live API</a> document.</p>
    <aside class="bcls-aside bcls-aside--tip">
      <p>This feature can also be enabled in Video Cloud Studio. For details, see the <a href="https://live.support.brightcove.com/live-module/creating-and-managing-live-events-using-live-module.html#create">Creating and Managing Live Events</a> document.</p>
     </aside>
     <h3 id="Setup">Setup</h3>
    <p>Live automated captions are available to Video Cloud customers. Contact Brightcove customer support to enable your account. </p>
    <p>Once you have enabled your account, then you can turn on automated captions for each live stream that you create.</p>
  </section>

  <!-- <section class="bcls-section">
    <h2 id="Requirements">Requirements</h2>

    <p>There are a few requirements for multiple language audio tracks.</p>
  
  </section> -->

  <section class="bcls-section">
    <h2 id="Turn_on_automated_captions">Turn on automated captions</h2>
    <p>To create a job with transcribe support for automated captions, add the following attributes to the regular Job creation payload:</p>

<pre class="line-numbers"><code class="language-json" translate="No">{
  &quot;manifest_api&quot;: {
    &quot;enabled&quot;: true
},
&quot;transcribe_state&quot;: &quot;ON&quot;
}</code></pre>  

  <h3 id="example">Example</h3>
  <p>This example body will create a live job with automated captions.</p>
  <h4>Request</h4>
<pre><code class="language-http" translate="No">POST https://api.bcovlive.io/v1/jobs
Content-Type: application/json
X-API-KEY: <span class="bcls-input">your_API_key</span></code></pre>

  <h4>Request body</h4>
  <pre class="line-numbers"><code class="language-json" translate="No">{
  "live_stream": true,  
  "region": "us-west-2",
  "reconnect_time": 1800,
  "live_sliding_window_duration": 1,
<span class="bcls-highlight">  "manifest_api": {
        "enabled": true
  },
  "transcribe_state": "ON",</span>
  "outputs": [
      {
          "label": "hls1080p",
          "live_stream": true,
          "width": 1920,
          "height": 1080,
          "video_codec": "h264",
          "h264_profile": "main",
          "video_bitrate": 2400,
          "segment_seconds": 6,
          "keyframe_interval": 60
      },
      {
          "label": "hls720p",
          "live_stream": true,
          "width": 1280,
          "height": 720,
          "video_codec": "h264",
          "h264_profile": "main",
          "video_bitrate": 1843,
          "segment_seconds": 6,
          "keyframe_interval": 60
      },
      {
          "label": "hls480p",
          "live_stream": true,
          "width": 640,
          "height": 360,
          "video_codec": "h264",
          "h264_profile": "main",
          "video_bitrate": 819,
          "segment_seconds": 6,
          "keyframe_interval": 60
      }
  ]
}</code></pre>

  <!-- <details>
    <summary><h4>Sample response</h4></summary>
<pre class="line-numbers"><code class="language-json" translate="No">{
"id": "76f814fbcd7840e99ebf0e335c933730",
"outputs": [
    {
        "id": "0-76f814fbcd7840e99ebf0e335c933730",
        "playback_url": "https://playback-qa.a-live.io/76f814fbcd7840e99ebf0e335c933730/us-west-2/NA/profile_0/chunklist.m3u8",
        "playback_url_dvr": "https://playback-qa.a-live.io/76f814fbcd7840e99ebf0e335c933730/us-west-2/NA/profile_0/chunklist_dvr.m3u8",
        "playback_url_vod": "https://playback-qa.a-live.io/76f814fbcd7840e99ebf0e335c933730/us-west-2/NA/profile_0/chunklist_vod.m3u8",
        "playback_added_cdns": [],
        "label": "hls720p"
    },
    {
        "id": "1-76f814fbcd7840e99ebf0e335c933730",
        "playback_url": "https://playback-qa.a-live.io/76f814fbcd7840e99ebf0e335c933730/us-west-2/NA/profile_1/chunklist.m3u8",
        "playback_url_dvr": "https://playback-qa.a-live.io/76f814fbcd7840e99ebf0e335c933730/us-west-2/NA/profile_1/chunklist_dvr.m3u8",
        "playback_url_vod": "https://playback-qa.a-live.io/76f814fbcd7840e99ebf0e335c933730/us-west-2/NA/profile_1/chunklist_vod.m3u8",
        "playback_added_cdns": [],
        "label": "hls540p"
    },
    {
        "id": "2-76f814fbcd7840e99ebf0e335c933730",
        "playlist_type": "defaultS3",
        "type": "playlist",
        "alternate_audio": {
            "tracks": [
                {
                    "label": "English",
                    "language": "en",
                    "name": "Alt0",
                   
                    "pid": 257,
                    "playlistDefault": true,
                    "default": true,
                    "variant": "main",
                    "profile_sources": [
                        "profile_0"
                    ]
                },
                {
                    "label": "Spanish",
                    "language": "es",
                    "name": "Alt1",
                    
                    "pid": 258,
                    "playlistDefault": false,
                    "default": false,
                    "variant": "main",
                    "profile_sources": [
                        "profile_0"
                    ]
                }
            ]
        },
        "filename": "playlist.m3u8",
        "dvr_filename": "playlist_dvr.m3u8",
        "playback_url": "https://playback-qa.a-live.io/76f814fbcd7840e99ebf0e335c933730/us-west-2/NA/playlist.m3u8",
        "playback_url_dvr": "https://playback-qa.a-live.io/76f814fbcd7840e99ebf0e335c933730/us-west-2/NA/playlist_dvr.m3u8",
        "playback_added_cdns": []
    }
],
<span class="bcls-highlight">"stream_url": "rtp://ep3-usw2.a-live.io:11780"</span>,
"stream_name": "76f814fbcd7840e99ebf0e335c933730.stream",
"static": false,
"alternate_audio": {
    "tracks": [
        {
            "label": "English",
            "language": "en",
            "pid": 257,
            "default": true,
            "variant": "main",
            "name": "Alt0"
        },
        {
            "label": "Spanish",
            "language": "es",
            "pid": 258,
            "default": false,
            "variant": "main",
            "name": "Alt1"
        }
    ]
},
"event_length": 93600,
"encryption": {},
<span class="bcls-highlight">"playback_url": "https://playback-qa.a-live.io/76f814fbcd7840e99ebf0e335c933730/us-west-2/NA/playlist.m3u8"</span>,
"playback_url_dvr": "https://playback-qa.a-live.io/76f814fbcd7840e99ebf0e335c933730/us-west-2/NA/playlist_dvr.m3u8",
"playback_added_cdns": []
}
</code></pre>
  </details> -->

  </section>

  <section class="bcls-section">
    <h2 id="Set_the_language">Set the language</h2>
    <p>You can set the language for the generated captions. In this example, the language is set to English, US:</p>
    <!-- <p>You can set the language for the generated captions. In this example, the language is set to Spanish, US:</p> -->
    <aside class="bcls-aside bcls-aside--information">
      Currently, only English (en-US) is supported for automated captions, and it is the default value.
     </aside>
    <pre class="line-numbers"><code class="language-json" translate="No">{
  &quot;manifest_api&quot;: {
    &quot;enabled&quot;: true
  },
  &quot;transcribe_state&quot;: &quot;ON&quot;,
  &quot;transcribe_options&quot;: {
      &quot;language_code&quot;: &quot;en-US&quot;
  }
}</code></pre>

    <!-- <p>You also have the flexibility to let the system infer the language of the ingest stream by specifying a list of probable languages.</p>
     <aside class="bcls-aside bcls-aside--information">
      Notes:
      <ul>
        <li>You should not provide both <code translate="No">language_code</code> and <code translate="No">language_detection</code> together. If they both are provided then <code translate="No">language_code</code> takes the precedence.</li>
        <li>You cannot provide input languages as the same language in different dialects. For example, you cannot provide <code translate="No">[“en-US”, “en-AU”]</code> as an input for <code translate="No">probable_input_languages</code>.</li>
      </ul>
     </aside>
<pre class="line-numbers"><code class="language-json" translate="No">{
  &quot;manifest_api&quot;: {
    &quot;enabled&quot;: true
  },
  &quot;transcribe_state&quot;: &quot;ON&quot;,
  &quot;transcribe_options&quot;: {
      &quot;language_detection&quot;: {
          &quot;auto_detect_language&quot;: true,
          &quot;probable_input_languages&quot;: [&quot;es-US&quot;, &quot;en-US&quot;],
          &quot;preferred_language&quot;: &quot;en-US&quot;
      }
  }
}</code></pre> -->
      
  </section>

  <section class="bcls-section">
    <h2 id="Turn_on_captions_mid_stream">Turn on captions mid stream</h2>
    <p>Enabling automated captions is supported after the job has been created any time independent of the job state. New Endpoints have been defined and shall be shared shortly to accomplish the sam.</p>
    <p>The endpoint would be:</p>

<pre class="line-numbers"><code class="language-json" translate="No">PATCH https://alive-auth.api.brightcove.com/v2/accounts/{{account_id}}/{job_region}/jobs/{job_id}/transcribe

  Payload:
  {
    &quot;transcribe_state&quot;: &quot;ON&quot;/&quot;OFF&quot;
  }</code></pre>  
  <aside class="bcls-aside bcls-aside--information">
    Turning Transcription ON/OFF will not impact existing playback sessions. Players must refresh for the changes to take effect because the master manifest is not fetched once playback begins. New sessions will start with Master manifest fetch so they'll align with the current state of transcribe flag.
   </aside>
  </section>

  <section class="bcls-section">
    <h2 id="Limitations">Limitations</h2>
    <p>Here is a list of limitations with the live automated captions feature:</p>
    <ul>
      <li>Transcription is only supported for non low latency HLS Streams. Low Latency HLS and DASH streams don't have transcription support at this time.</li>
      <!-- <li>Transcription support is built on top of capabilities exposed via the Manifest API. So, <strong>manifest-api</strong> support has to be enabled on your account. The playback URL exposed via the Manifest API is the only manifest that supports subtitles in them and not the one from our S3 origin.</li> -->
      <li>You cannot enable Transcribe support for Jobs already created in your account.</li>
      <li>Currently, we provide captions only in one language. We don't support multi language captions at the moment. The Default language for captions is set to <code translate="No">en-US</code></li>
      <li>Automated captions work best for jobs less than 4 hours in duration. If your live stream exceeds 4 hours, captions may drop for a brief interval.</li>
    </ul>
  </section>

  <!-- <section class="bcls-section">
    <h2 id="AWS_Limitations">AWS Limitations</h2>
    <p>Some limitations are specific to how Amazon transcribes speech to text. For details, see the <a href="https://docs.aws.amazon.com/transcribe/latest/dg/how-it-works.html">How Amazon Transcribe works</a> document.</p>
    <ul>
      <li>The number of concurrent streaming transcriptions is set to 25 which can be increased by requesting a quota increase. Based on AWS TAM Inputs, the typical turnaround is ~1 week.</li>
      <li>The maximum limit for audio file duration that can be sent to AWS for transcribing (both file / streaming) is capped at 4 hours. This seems to be a hard limit that can't be raised. This means that the connection will go down and be re-established automatically when the 4 hours streaming limit is exceeded, resulting in non availability of captions during that interval.</li>
    </ul>
  </section> -->

  <section>
     <!-- <h3>Supported fields for the <code translate="No">Track</code> object</h3>
    <p>The table below contains a full description of supported fields in the <code translate="No">track</code> object.</p>
    <table class="bcls-table">
      <caption class="bcls-caption--table">Track Fields</caption>
      <thead class="bcls-table__head">
          <tr>
              <th>Field</th>
              <th>Type</th>
              <th>Required</th>
              <th>Description</th>
          </tr>
      </thead>
      <tbody class="bcls-table__body">
        <tr>
          <td><code translate="No">language</code></td>
          <td>string</td>
          <td>Yes</td>
          <td>
            <p>The code for the language to be used; at present this is flexible and could be in any of the various language formats required/supported by the specs, specifically <a href="https://tools.ietf.org/html/rfc5646">RFC5456/BCP47</a> which also covers ISO-639 as per the requirements</p> 
            <p>HLS &gt; <code translate="No">LANGUAGE</code> field</p>
            <p>DASH &gt; <code translate="No">AdaptationSet:lang</code> field</p>
          </td>
        </tr>
        <tr>
          <td><code translate="No">video_pid</code></td>
          <td>integer</td>
          <td>Yes</td>
          <td>The Packet Identifier (PID) from the MPEG-TS input stream for the video track</td>
        </tr>
        <tr>
          <td><code translate="No">pid</code></td>
          <td>integer</td>
          <td>Yes</td>
          <td>The Packet Identifier (PID) from the MPEG-TS input stream for a specific audio track</td>
        </tr>
        <tr>
          <td><code translate="No">default</code></td>
          <td>boolean</td>
          <td>Yes (for the default track)</td>
          <td>
            The audio track marked as <code translate="No">DEFAULT</code> in the <code translate="No">EXT-X-MEDIA</code> as well as the track to be muxed into video stream
            <p>If not present, the first track is the default.</p>
            <p>If multiple playlists are defined with different defaults, the top level default track is the muxed one.</p>
          </td>
        </tr>
        <tr>
          <td><code translate="No">label</code></td>
          <td>string</td>
          <td></td>
          <td>A text description to be used for the track, preferred to be used by the player where possible; used in: HLS &gt; <code translate="No">NAME</code> field
            <p>Default: the <code translate="No">language</code> with an ID for each track e.g. <code translate="No">en-0</code> if not specified</p>
          </td>
        </tr>
        <tr>
          <td><code translate="No">variant</code></td>
          <td>enum</td>
          <td></td>
          <td>
            Maps to the DASH Role Schema values: 
            <ul>
              <li><code translate="No">main</code></li>
              <li><code translate="No">alternate</code></li>
              <li><code translate="No">commentary</code></li>
              <li><code translate="No">supplementary</code></li>
              <li><code translate="No">dub</code></li>    
            </ul>
            <p>HLS &gt; <a href="https://tools.ietf.org/html/rfc8216#section-4.3.4.1">CHARACTERISTICS</a></p>
            <p>DASH &gt; Role <code translate="No">urn:mpeg:dash:role:2011</code>.</p>
            <p>Default: <code translate="No">main</code></p>
          </td>
        </tr>
        <tr>
          <td><code translate="No">streams</code> []</td>
          <td>array</td>
          <td></td>
          <td>
            <p>This mimics the <code translate="No">streams</code> field of the playlist output type; example: <code translate="No">{ “source”: “720p” }</code> - matches the label of the output source</p>
            <p>If not present, uses the default audio settings.</p> 
            <p>HLS &gt; <code translate="No">GROUP-ID</code>. (Object)</p>
          </td>
        </tr>
      </tbody>
  </table> -->
  </section>

  
</article>